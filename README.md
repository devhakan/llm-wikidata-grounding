# LLM Wikidata Grounding

A fact-checking system that grounds claims against Wikidata's structured knowledge base using **vector search**, **cross-encoder reranking**, and **local LLM reasoning**.

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ What This Project Does

LLMs are powerful but prone to **hallucinations**. This project verifies claims against Wikidata using a hybrid pipeline:

```
Claim â†’ Vector Search â†’ Statement Retrieval â†’ Reranking â†’ Ollama LLM â†’ Verdict
```

### Example Results (Hybrid Pipeline)

| Claim | Verdict | Confidence |
|-------|---------|------------|
| "Aziz Sancar won the Nobel Prize in Chemistry in 2015" | âœ“ SUPPORTED | **90%** |
| "Ibn al-Haytham was born in Basra" | âœ“ SUPPORTED | 90% |
| "Ã–zlem TÃ¼reci is the co-founder of BioNTech" | âœ“ SUPPORTED | 90% |
| "Al-Khwarizmi lived in the 9th century" | âœ“ SUPPORTED | 90% |
| "Aziz Sancar won Nobel Prize in Physics in 2020" | âœ— REFUTED | 90% |
| "Einstein was born in France" | âœ— REFUTED | 90% |

> **Note**: Using local Ollama LLM (qwen2.5:7b) provides much higher confidence than NLI models (~58-76%).


---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLAIM: "Aziz Sancar won Nobel Prize in Chemistry in 2015"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. VECTOR SEARCH                                                    â”‚
â”‚     API: wd-vectordb.wmcloud.org                                     â”‚
â”‚     Result: Q15118973 (Aziz Sancar), Q44585 (Nobel Chemistry)...     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. STATEMENT RETRIEVAL                                              â”‚
â”‚     API: wikidata.org/w/api.php (wbgetclaims)                        â”‚
â”‚     Result: 131 statements about matched entities                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. CROSS-ENCODER RERANKING                                          â”‚
â”‚     Model: cross-encoder/ms-marco-MiniLM-L-6-v2                      â”‚
â”‚     Result: Top 10 relevant statements                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. OLLAMA LLM REASONING                                             â”‚
â”‚     Model: qwen2.5:7b (local)                                        â”‚
â”‚     Natural language understanding of evidence vs claim              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VERDICT: âœ“ SUPPORTED (90%)                                          â”‚
â”‚  "Evidence clearly states Aziz Sancar won Nobel Prize in 2015"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.ai) with a model installed (e.g., `qwen2.5:7b`)
- ~1GB disk space (for reranker model)

### Quick Start

```bash
# Clone
git clone https://github.com/devhakan/llm-wikidata-grounding.git
cd llm-wikidata-grounding

# Virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install
pip install -r requirements.txt

# Ensure Ollama is running with a model
ollama pull qwen2.5:7b
ollama serve  # if not already running

# Verify
python verify_setup.py
```

---

## ğŸš€ Usage

### Command Line (Hybrid Pipeline)

```bash
# Single claim
python src/hybrid_pipeline.py "Aziz Sancar won Nobel Prize in Chemistry"

# Verbose mode
python src/hybrid_pipeline.py -v "Ibn al-Haytham was born in Basra"

# Interactive mode
python src/hybrid_pipeline.py
```

### Python API

```python
from src.hybrid_pipeline import HybridFactChecker, verify

# Quick check
result = verify("Ã–zlem TÃ¼reci is the co-founder of BioNTech", verbose=True)
print(result.verdict)      # "SUPPORTED"
print(result.confidence)   # 0.9
print(result.reasoning)    # "Evidence shows..."

# With custom model
checker = HybridFactChecker(model="qwen2.5:7b", verbose=True)
result = checker.check("Al-Khwarizmi lived in the 9th century")
```

---

## ğŸ”¬ Components

### 1. Vector Search
Semantic search using Wikidata's experimental vector database:
```python
from src.wikidata_api import vector_search
results = vector_search("Turkish scientist Nobel Prize")
# â†’ [{"id": "Q15118973", "score": 0.86}, ...]
```

### 2. Cross-Encoder Reranking
Filter thousands of statements to the most relevant:
```python
from src.reranker import Reranker
reranker = Reranker()
ranked = reranker.rerank(claim, statements, top_k=10)
```

### 3. Ollama LLM Classification
Natural language reasoning with local LLM:
```python
from src.ollama_classifier import OllamaClassifier
classifier = OllamaClassifier(model="qwen2.5:7b")
result = classifier.classify(claim, evidence)
```

---

## ğŸ“Š Verdict Types

| Verdict | Meaning |
|---------|---------|
| âœ“ **SUPPORTED** | Evidence confirms the claim |
| âœ— **REFUTED** | Evidence contradicts the claim |
| ? **NOT_ENOUGH_INFO** | Insufficient evidence |

---

## âš™ï¸ Configuration

### Ollama Models

Any Ollama model works. Tested with:
- `qwen2.5:7b` (recommended)
- `llama3.2`
- `mistral`

```bash
# Pull a model
ollama pull qwen2.5:7b

# Use in code
checker = HybridFactChecker(model="qwen2.5:7b")
```

---

## ğŸ“ Project Structure

```
llm-wikidata-grounding/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ wikidata_api.py      # Vector search + Wikidata APIs
â”‚   â”œâ”€â”€ reranker.py          # Cross-Encoder reranking
â”‚   â”œâ”€â”€ ollama_classifier.py # Ollama LLM classification
â”‚   â”œâ”€â”€ hybrid_pipeline.py   # Main hybrid pipeline â­
â”‚   â”œâ”€â”€ pipeline.py          # NLI-based pipeline (alternative)
â”‚   â””â”€â”€ nli_classifier.py    # NLI model (alternative)
â”œâ”€â”€ examples/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ verify_setup.py
â””â”€â”€ README.md
```

---

## ğŸ™ Acknowledgments

- **Philippe Saade** (Wikimedia Deutschland) - Wikidata Vector Database & workshop
- **Jonathan Fraine** (Wikimedia) - Wikidata in the AI Web
- **Wikidata community** - Maintaining the knowledge base

---

## ğŸ‘¤ Author

Created by **[User:HakanIST](https://www.wikidata.org/wiki/User:HakanIST)** - Wikimedia volunteer & Wikidata contributor.

- ğŸŒ [Wikidata User Page](https://www.wikidata.org/wiki/User:HakanIST)
- ğŸ’» [GitHub](https://github.com/devhakan)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)
